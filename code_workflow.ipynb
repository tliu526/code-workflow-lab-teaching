{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Code Workflows and Python Tooling for Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## My experience: a balancing act\n",
    "\n",
    "<center><img src=\"images/ss_shipit.jpg\" width=\"500\"></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- \"just shipping it\" vs. \"coding the *right way*\"\n",
    "- improving workflows is a process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- \"just ship it\" mentality\n",
    "- \"technical debt\" analogy: the uncertainty of research makes taking on technical debt that much easier\n",
    "- try to start building habits that make \"doing things the right way\" efficient\n",
    "- it is a process: don't expect yourself to change all at once, make incremental improvements in workflow\n",
    "- also about building the right habits\n",
    "- will go through some not so great examples (from yours truly), some easy things to always do, some things to try and incorporate into your workflow, as well as some more involved setups\n",
    "- something easy to do and should be done, med, hard\n",
    "- will focus on Python here, but the same tooling exists and principles apply to other languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "- Documentation\n",
    "- Testing\n",
    "- Version Control\n",
    "- Automation\n",
    "- Reproducibility\n",
    "- Workflow Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Documentation\n",
    "\n",
    "1. Comment __while__ you code\n",
    "2. Ideally, follow a Docstring style\n",
    "3. Consider documentation generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Write comments as you go: your future self will thank you\n",
    "- Use inline comments `#` to provide context\n",
    "- Use docstrings `\"\"\" \"\"\"` to describe the behavior of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Not good\n",
    "def f(n):\n",
    "    return 1 << n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Better\n",
    "def power_of_two(n):\n",
    "    \"\"\"Calculates 2^n.\"\"\"\n",
    "    \n",
    "    # left bit shift by n equivalent to 2^n.\n",
    "    return 1 << n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function power_of_two in module __main__:\n",
      "\n",
      "power_of_two(n)\n",
      "    Calculates 2^n.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(power_of_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Disclaimer: do not reinvent the wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def power_of_two(n):\n",
    "    \"\"\"Calculates 2^n, but n can be negative and non-integer now!\"\"\"\n",
    "    return np.power(2, n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Not good\n",
    "def f(l):\n",
    "    ps = []\n",
    "    n = len(l)\n",
    "    for i in range(1<<n):\n",
    "        s = [l[j] for j in range(n) if (i & 1 << j)]\n",
    "        ps.append(s)\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Better\n",
    "def powerset(l):\n",
    "    \"\"\"Returns the power set of l.\"\"\"\n",
    "    \n",
    "    ps = []\n",
    "    n = len(l)\n",
    "    # use n-bit binary number to indicate whether an item is included in a set\n",
    "    for i in range(1<<n):\n",
    "        # generate subset by checking which bits are 1 in i\n",
    "        s = [l[j] for j in range(n) if (i & 1 << j)]\n",
    "        ps.append(s)\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Disclaimer: do not reinvent the wheel\n",
    "# itertools-provided recipe for powerset\n",
    "from itertools import chain, combinations\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "help(powerset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Docstring styles\n",
    "\n",
    "- reST, Numpy, Google standardized documentation styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Google-style docstrings\n",
    "def power_of_two(n):\n",
    "    \"\"\"(Short description): Calculates 2^n.\n",
    "    \n",
    "    (Longer description): Calculates non-negative powers of two via bit shift.\n",
    "    \n",
    "    Args:\n",
    "        n (int): the exponent to raise 2 to.\n",
    "    Returns:\n",
    "        int: 2^n.\n",
    "    Raises:\n",
    "       ValueError: if n < 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    # left bit shift by n equivalent to 2^n.\n",
    "    return 1 << n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function power_of_two in module __main__:\n",
      "\n",
      "power_of_two(n)\n",
      "    (Short description): Calculates 2^n.\n",
      "    \n",
      "    (Longer description): Calculates non-negative powers of two via bit shift.\n",
      "    \n",
      "    Args:\n",
      "        n (int): the exponent to raise 2 to.\n",
      "    Returns:\n",
      "        int: 2^n.\n",
      "    Raises:\n",
      "       ValueError: if n < 0.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(power_of_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consider documentation generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def power_of_two(n):\n",
      "    \"\"\"Calculates :math:`2^n`.\n",
      "    \n",
      "    Calculates non-negative powers of two via bit shift.\n",
      "    \n",
      "    Args:\n",
      "        n (int): the exponent to raise 2 to.\n",
      "    Returns:\n",
      "        int: :math:`2^n`.\n",
      "    Raises:\n",
      "       ValueError: if :math:`n \\lt 0`.\n",
      "    \"\"\"\n",
      "    \n",
      "    # left bit shift by n equivalent to 2^n.\n",
      "    return 1 << n\n",
      "make: Entering directory '/mnt/c/Users/1994t/Documents/Github/code-workflow-lab-teaching/sphinx_demo'\n",
      "\u001b[01mRunning Sphinx v1.8.5\u001b[39;49;00m\n",
      "\u001b[01mloading pickled environment... \u001b[39;49;00mdone\n",
      "\u001b[01mbuilding [mo]: \u001b[39;49;00mtargets for 0 po files that are out of date\n",
      "\u001b[01mbuilding [html]\u001b[39;49;00m: targets for 0 source files that are out of date\n",
      "\u001b[01mupdating environment: \u001b[39;49;00m0 added, 0 changed, 0 removed\n",
      "\u001b[01mlooking for now-outdated files... \u001b[39;49;00mnone found\n",
      "\u001b[01mno targets are out of date.\u001b[39;49;00m\n",
      "\u001b[01mbuild succeeded.\u001b[39;49;00m\n",
      "\n",
      "The HTML pages are in _build/html.\n",
      "make: Leaving directory '/mnt/c/Users/1994t/Documents/Github/code-workflow-lab-teaching/sphinx_demo'\n"
     ]
    }
   ],
   "source": [
    "! cat sphinx_demo/code/power_of_two.py\n",
    "! make -C sphinx_demo html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"images/sphinx_doc.PNG\" width=\"1500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Testing\n",
    "\n",
    "\"The first principle is that you must not fool yourself — and you are the easiest person to fool.\" — Richard Feynman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- defensive coding\n",
    "- research code scares me -- since often we don't know what's \"correct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Testing\n",
    "\n",
    "1. Think about what your code \"should do\"\n",
    "2. Write dedicated tests while you code\n",
    "3. Consider testing frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- we all write tests -- little print statements to verify the output, etc\n",
    "- but we end up throwing them away"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Test-driven development mindset\n",
    "\n",
    "- write code to pass tests -> makes coding sessions more directed\n",
    "- forces you to think about failure points in your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fizzbuzz example\n",
    "\n",
    "- `fizzbuzz` function, on input `n`:\n",
    "    - if n is divisible by 3, print \"fizz\"\n",
    "    - if n is divisible by 5, print \"buzz\"\n",
    "    - if n is divisible by both 3 and 5, print \"fizzbuzz\"\n",
    "    - otherwise, output n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def fizzbuzz(n):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# assert statements are your friend\n",
    "assert fizzbuzz(3) == 'fizz', 'fails divides by 3 case'\n",
    "assert fizzbuzz(5) == 'buzz', 'fails divides by 5 case'\n",
    "assert fizzbuzz(15) == 'fizzbuzz', 'fails divides by 15 case'\n",
    "assert fizzbuzz(1) == 1, 'fails else case'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- don't delete the assert statements! They help you regression test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Docstrings part II: testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def fizzbuzz(n):\n",
    "    \"\"\"Performs the fizzbuzz function on input n.\n",
    "    \n",
    "    Doctests for regression testing, and examples of usage:\n",
    "    \n",
    "    >>> fizzbuzz(3)\n",
    "    'fizz'\n",
    "    >>> fizzbuzz(5)\n",
    "    'buzz'\n",
    "    >>> fizzbuzz(15)\n",
    "    'fizzbuzz'\n",
    "    >>> fizzbuzz(1)\n",
    "    1\n",
    "    \"\"\"\n",
    "    out = \"\"\n",
    "    if n % 3 == 0: out += \"fizz\"\n",
    "    if n % 5 == 0: out += \"buzz\"\n",
    "    return out if len(out) > 0 else n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import doctest\n",
    "doctest.testmod(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consider testing frameworks like `unittest`\n",
    "\n",
    "- provides automation, shared setup/teardown of tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Unit tests for feature extraction methods.\n",
    "\n",
    "\n",
    "Test contact hashes are:\n",
    "['1002060a7f4fe408f8137f12982e5d64cf34693',\n",
    "'10413044ad5f1183e38f5ddf17259326e976231']\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unittest\n",
    "\n",
    "class FeatureExtractTests(unittest.TestCase):\n",
    "\n",
    "    def assert_frame_equal_dict(self, actual_df, expected_dict, columns, check_dtype=True):\n",
    "        \"\"\"Helper function for doing df to dict comparison on the given columns.\"\"\"\n",
    "\n",
    "        expected_df = pd.DataFrame.from_dict(expected_dict).T\n",
    "        expected_df.columns = columns\n",
    "\n",
    "        pd.testing.assert_frame_equal(actual_df[columns],\n",
    "                                      expected_df,\n",
    "                                      check_dtype=check_dtype)\n",
    "\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"Populates test DataFrames common to all test cases.\"\"\"\n",
    "        self.pid1 = '1002060'\n",
    "        self.pid2 = '1041304'\n",
    "\n",
    "        self.combined_hash1 = '1002060a7f4fe408f8137f12982e5d64cf34693'\n",
    "        self.combined_hash2 = '10413044ad5f1183e38f5ddf17259326e976231'\n",
    "\n",
    "        with open(\"../data/test_comm.df\", 'rb') as comm_file:\n",
    "            self.raw_df = pickle.load(comm_file)\n",
    "            self.call_df = self.raw_df.loc[self.raw_df['comm_type'] == 'PHONE']\n",
    "            self.sms_df = self.raw_df.loc[self.raw_df['comm_type'] == 'SMS']\n",
    "\n",
    "        with open(\"../data/test_emm.df\", 'rb') as emm_file:\n",
    "            self.emm_df = pickle.load(emm_file)\n",
    "\n",
    "\n",
    "    def test_init_feature_df(self):\n",
    "        \"\"\"\"Tests init_feature_df function.\n",
    "        \n",
    "        Checks whether total_comms, total_comm_days, and contact_type columns are populated correctly.\n",
    "        \"\"\"\n",
    "        expected_dict = {\n",
    "            (self.pid1, self.combined_hash1): [8, 2, 'friend'],\n",
    "            (self.pid2, self.combined_hash2): [6, 3, 'family_live_together']\n",
    "        }\n",
    "\n",
    "        expected_df = pd.DataFrame.from_dict(expected_dict).T\n",
    "        expected_df.index = expected_df.index.rename(['pid', 'combined_hash'])\n",
    "        expected_df = expected_df.rename({\n",
    "                                            0: \"total_comms\",\n",
    "                                            1: \"total_comm_days\",\n",
    "                                            2: \"contact_type\"\n",
    "                                         },\n",
    "                                         axis='columns')\n",
    "        expected_df['total_comms'] = expected_df['total_comms'].astype(int)\n",
    "        expected_df['total_comm_days'] = expected_df['total_comm_days'].astype(int)\n",
    "        \n",
    "        actual_df = init_feature_df(self.raw_df)\n",
    "\n",
    "        pd.testing.assert_frame_equal(actual_df, expected_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "(code-workflow) tliu@DESKTOP-3QP831J:feature_extract$ python test_feature_extract.py -v\n",
    "test_build_avoidance_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_channel_selection_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_count_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_demo_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_duration_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_holiday_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_intensity_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_maintenance_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_temporal_features (__main__.FeatureExtractTests) ... ok\n",
    "test_filter_by_holiday (__main__.FeatureExtractTests) ... ok\n",
    "test_init_feature_df (__main__.FeatureExtractTests) ... ok\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Ran 11 tests in 2.086s\n",
    "\n",
    "OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Version Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Version Control\n",
    "\n",
    "0. Use it!\n",
    "1. Commit messages should be informative\n",
    "2. Ideally subdivide tasks into concrete commits\n",
    "3. Consider branching strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Commit Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<center><img src=\"images/bad_commits.PNG\" width=\"500\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Commit Messages\n",
    "\n",
    "- Summarize commit in brief, imperative statement\n",
    "- Use commit body for more details if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consider Development Branches\n",
    "\n",
    "- treat `master` as \"protected\" branch\n",
    "- work on new features in separate branches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Development Branch Workflow\n",
    "\n",
    "![](images/feature_branch_01.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# create new branch, dev-branch\n",
    "git checkout -b dev-branch master\n",
    "\n",
    "# do work\n",
    "git add ...\n",
    "git commit ...\n",
    "\n",
    "# push to remote dev-branch, open PR\n",
    "git push origin dev-branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](images/feature_branch_02.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Thoughts on Code Review\n",
    "\n",
    "- \"could you read my paper draft?\" -> \"could you review my code?\"\n",
    "\n",
    "<center><img src=\"images/code_review.PNG\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automation \n",
    "\n",
    "1. Move your work out of \"interactive mode\" as often as possible\n",
    "2. Ideally batch process computation\n",
    "3. Consider workflow automation tools like `make`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `argparse` is your friend\n",
    "\n",
    "- allows parameterization of entire modules\n",
    "- another form of documentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"Extract data from Optum raw files and dump to DataFrames\")\n",
    "parser.add_argument('data_dir', help='directory with all Optum data')\n",
    "parser.add_argument('yr', help='the year to target')\n",
    "parser.add_argument('q', help='the quarter to target')\n",
    "parser.add_argument('out_dir', help='output directory')\n",
    "parser.add_argument('table_type', choices=['m', 'lr', 'r'], help='Optum table type to target: medical (m), lab reports (lr), prescriptions (r)')\n",
    "parser.add_argument('chunksize', type=int, help='number of rows to read per chunk')\n",
    "parser.add_argument('--test', action='store_true', help='whether to make a test run of the data extraction')\n",
    "parser.add_argument('--m_dm_outcome', action='store_true', help='perform diabetes med outcome extraction')\n",
    "parser.add_argument('--rx_dm', action='store_true', help='perform diabetes rx extraction')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: med_extract.py [-h] [--test] [--m_dm_outcome] [--rx_dm]\r\n",
      "                      data_dir yr q out_dir {m,lr,r} chunksize\r\n",
      "\r\n",
      "Extract data from Optum raw files and dump to DataFrames\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  data_dir        directory with all Optum data\r\n",
      "  yr              the year to target\r\n",
      "  q               the quarter to target\r\n",
      "  out_dir         output directory\r\n",
      "  {m,lr,r}        Optum table type to target: medical (m), lab reports (lr),\r\n",
      "                  prescriptions (r)\r\n",
      "  chunksize       number of rows to read per chunk\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help      show this help message and exit\r\n",
      "  --test          whether to make a test run of the data extraction\r\n",
      "  --m_dm_outcome  perform diabetes med outcome extraction\r\n",
      "  --rx_dm         perform diabetes rx extraction\r\n"
     ]
    }
   ],
   "source": [
    "! python scripting_demo/med_extract.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- argparse is yet another form of documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# nohup means ignore hangup (logouts), ampersand means run in the background\n",
    "nohup python batch_example.py &\n",
    "\n",
    "# alternatively, use tmux/screen window managers\n",
    "tmux new -s batch_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- much better than running python ... (especially better than running a computation in jupyter)\n",
    "- more sophisticated way of scheduling jobs in the background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consider `make` for complex workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- used for building software, can be also used for data transformation\n",
    "- disclaimer: I haven't yet encountered a workflow in my research career that make makes significantly easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# command from earlier to build documentation\n",
    "sphinx-build . _build -b html\n",
    "\n",
    "# Makefile equivalent\n",
    "make html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "! cat sphinx_demo/Makefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reproducibility\n",
    "\n",
    "1. Parameterize code to facilitate A/B testing\n",
    "2. Ideally, track and parameterize your environment too\n",
    "3. Consider Docker for more complex builds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bash scripts\n",
    "\n",
    "- Code form of an experimental procedure\n",
    "- gives us a mechanism to track changes in runs, A/B testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "! cat scripting_demo/tie_str_rf_reg.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tracking your environment\n",
    "\n",
    "- use `virtualenv` or `conda` to make your environments portable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "! conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "! conda env export > environment.yml\n",
    "! cat environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consider Docker for complex environments\n",
    "\n",
    "- port, share and reproduce \"OS-level\" configurations\n",
    "    - custom library installations (eg, CUDA)\n",
    "    - UNIX tooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Jupyter notebooks are __notebooks__\n",
    "\n",
    "- good for exploring the data\n",
    "- good for presenting and visualizing results\n",
    "- bad for \"doing work\" in between"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Jupyter notebook bloat\n",
    "\n",
    "- A cell that looks like [this](https://gist.github.com/tliu526/6e23aa99a323646be98691fb6d6a0f55):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def build_hist(series, bins, xtick_labels, xlabel, title):\n",
    "    \"\"\"\n",
    "    Builds custom histogram with bar labels and equal bin sizes\n",
    "    \n",
    "    :param series: pandas series to bin\n",
    "    :param bins: list of bin sizes\n",
    "    :param xtick_labels: list of labels for xticks\n",
    "    :param xlabel: x-axis str label\n",
    "    :param title: str title\n",
    "    \"\"\"\n",
    "    counts, _ = np.histogram(series.values, bins=bins)\n",
    "    rects = plt.bar(range(len(counts)), counts, width=0.5, tick_label=counts)\n",
    "    for r in rects: \n",
    "        h = r.get_height()\n",
    "        plt.text(r.get_x() + r.get_width()/2, 1.01*h, h, ha='center')\n",
    "    plt.xticks(range(len(counts)), xtick_labels)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"# participants\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def get_score(row, source_df, score_name):\n",
    "    \"\"\"\n",
    "    Maps the score_name score from the given source DataFrame to a row by pid.\n",
    "    To be used via DataFrame.apply().\n",
    "    \n",
    "    Example usage: \n",
    "        all_df['score_AUDIT'] = all_df.apply(get_score, \n",
    "                                             source_df=screener_df, \n",
    "                                             score_name='score_AUDIT',\n",
    "                                             axis=1)\n",
    "    \"\"\"\n",
    "    \n",
    "    return source_df[source_df['pid'] == row.pid][score_name].values[0]\n",
    "\n",
    "\n",
    "def build_ttest_dfs(pid_df, group_col, val_cols):\n",
    "    \"\"\"\n",
    "    Runs t-tests on the given pid_df DataFrame against the groupings as defined in group_col.\n",
    "    \n",
    "    :param pid_df: a DataFrame aggregated by participant pids\n",
    "    :param group_col: the column name to group on\n",
    "    :param val_cols: the columns we want to run t-tests on\n",
    "    :returns: t_df, p_df DataFrames containing the t and p values\n",
    "    \"\"\"\n",
    "    index = pd.Index(data=pid_df[group_col].unique(), name=group_col).sort_values()\n",
    "    t_df = pd.DataFrame(index = index, columns = val_cols)\n",
    "    p_df = pd.DataFrame(index = index, columns = val_cols)\n",
    "\n",
    "    for group in pid_df[group_col].unique():\n",
    "        selected_group = pid_df[pid_df[group_col] == group]\n",
    "        rest_group =  pid_df[pid_df[group_col] != group]\n",
    "        for col in val_cols:\n",
    "            t, p = ttest_ind(selected_group[col].values, \n",
    "                             rest_group[col].values, \n",
    "                             nan_policy='omit')\n",
    "\n",
    "            t_df.loc[group][col] = t\n",
    "            p_df.loc[group][col] = p\n",
    "    \n",
    "    for col in p_df.columns.values:\n",
    "            t_df[col] = t_df[col].apply(lambda x: format(float(x), '.3f'))\n",
    "            p_df[col] = p_df[col].apply(lambda x: format(float(x), '.3f'))\n",
    "    return t_df, p_df\n",
    "\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "    \"\"\"\n",
    "    Concats the given DataFrame args to \n",
    "    \"\"\"\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        #for col in df.col.values:\n",
    "        #    df[col] = df[col].apply(lambda x: format(float(x), '2.3d'))\n",
    "        html_str+=df._repr_html_()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
    "    \n",
    "\n",
    "def build_csv_tables(csv_pid, csv_cols, bins, xlabels, score_col, group_col, show_bar=False, ylabel=\"\", title=\"\", alpha=0.05, width=0.7):\n",
    "    \"\"\"\n",
    "    Builds and displays descriptive statistics for the given csv Dataframe.\n",
    "    \n",
    "    :param csv_pid: DataFrame grouped by pid\n",
    "    :param csv_cols: the target csv column values to display\n",
    "    :param bins: the bins defined for the disorder score\n",
    "    :param xlabels: labels for each bin\n",
    "    :param score_col: the col name for the disorder score\n",
    "    :param group_col: the chosen group name for the bins\n",
    "    \"\"\"\n",
    "    csv_pid[group_col] = pd.cut(csv_pid[score_col], bins, labels=xlabels)\n",
    "    csv_pid = csv_pid.dropna(subset=[group_col])\n",
    "    csv_group = csv_pid.groupby(group_col)[csv_cols]\n",
    "\n",
    "    t, p = build_ttest_dfs(csv_pid, group_col, csv_cols)\n",
    "\n",
    "    display_side_by_side(csv_group.mean().style.set_caption(\"mean\"), \n",
    "                         csv_group.std().style.set_caption(\"std dev\"),\n",
    "                         p.style.set_caption(\"p-values\"))\n",
    "\n",
    "    \n",
    "    if show_bar:\n",
    "        yerr=csv_group.std().T\n",
    "        ax = csv_group.mean().T.plot.bar(yerr=yerr, width=width, rot=0)\n",
    "        p_list = p.values.flatten()\n",
    "        std_list = csv_group.std().values.flatten()\n",
    "        for i, bar in enumerate(ax.patches):\n",
    "            sig = \"*\" if float(p_list[i]) < alpha else \"\"\n",
    "            height = bar.get_height()\n",
    "            text = format(height, \".2f\") + sig\n",
    "            ax.annotate(text, (bar.get_x() + bar.get_width()/2, (height + std_list[i])*1.01), ha='center')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.title(title)\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "        \n",
    "    return csv_group, p\n",
    "\n",
    "\n",
    "def build_bar(std_df, mean_df, p_val_df, ylabel=\"\", title=\"\", alpha=0.05, show_legend=False):\n",
    "    \"\"\"\n",
    "    Builds a bar chart with the given DataFrames\n",
    "    \"\"\"\n",
    "    yerr=std_df.T\n",
    "    ax = mean_df.T.plot.bar(yerr=yerr, width=0.7, rot=0)\n",
    "    p_list = p_val_df.values.flatten()\n",
    "    std_list = std_df.values.flatten()\n",
    "    for i, bar in enumerate(ax.patches):\n",
    "        sig = \"*\" if float(p_list[i]) < alpha else \"\"\n",
    "        height = bar.get_height()\n",
    "        text = format(height, \".2f\") + sig\n",
    "        ax.annotate(text, (bar.get_x() + bar.get_width()/2, (height + std_list[i])*1.01), ha='center')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    if show_legend:\n",
    "        plt.legend(loc='lower right')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [15,6]\n",
    "\n",
    "\n",
    "def generate_ems_stats(ems_raw, bins, xlabels, score_col, group_name):\n",
    "    \"\"\"\n",
    "    Convenience method for generating ems.csv statistics.\n",
    "    \"\"\"\n",
    "    ems_pid = ems_raw.groupby('pid', as_index=False).mean()\n",
    "    group, p_vals = build_csv_tables(ems_pid, ems_cols, bins, xlabels, score_col, group_name, show_bar=False)\n",
    "    sleep_qual_mean = group.mean()['sleep_quality']\n",
    "    sleep_qual_std = group.std()['sleep_quality']\n",
    "    sleep_qual_p = p_vals['sleep_quality']\n",
    "    title = \"Average sleep quality for {} groups, significance* at alpha=0.05\".format(group_name)\n",
    "    ylabel = \"Average sleep quality 0-8 Likert\"\n",
    "    build_bar(mean_df=sleep_qual_mean, std_df=sleep_qual_std, p_val_df=sleep_qual_p, title=title, ylabel=ylabel)\n",
    "    \n",
    "\n",
    "def generate_emm_stats(emm_raw, bins, xlabels, score_col, group_name):\n",
    "    \"\"\"\n",
    "    Convenience method for processing emm.csv statistics\n",
    "    \"\"\"\n",
    "    emm_pid = emm_raw.groupby('pid', as_index=False).mean()\n",
    "    ylabel = \"Average EMA score 0-8 Likert\" \n",
    "    title = \"Average EMA responses for {} groups, significance at alpha=0.05\".format(group_name)\n",
    "    group, p = build_csv_tables(emm_pid, emm_cols, bins, xlabels, score_col, group_name, show_bar=True, ylabel=ylabel, title=title)\n",
    "    \n",
    "\n",
    "def generate_coe_stats(coe, bins, xlabels, score_col, group_name):\n",
    "    \"\"\"\n",
    "    Convenience method for processing coe.csv statistics\n",
    "    \"\"\"\n",
    "    coe_pid = coe.groupby('pid', as_index=False).mean()\n",
    "    ylabel = \"Average daily frequency\" \n",
    "    title = \"Average communication daily counts for {} groups, significance at alpha=0.05\".format(group_name)\n",
    "    group, p = build_csv_tables(coe_pid, coe_cols, bins, xlabels, score_col, group_name, show_bar=True, ylabel=ylabel, title=title)\n",
    "    \n",
    "\n",
    "def generate_scr_stats(scr, bins, xlabels, score_col, group_name):\n",
    "    \"\"\"\n",
    "    Convenience method for processing scr.csv statistics\n",
    "    \"\"\"\n",
    "    scr_pid = scr.groupby('pid', as_index=False).mean()\n",
    "    ylabel = \"Average screen on hours\" \n",
    "    title = \"Average screen on time for {} groups, significance at alpha=0.05\".format(group_name)\n",
    "    group, p = build_csv_tables(scr_pid, ['screen_on'], bins, xlabels, score_col, group_name, show_bar=True, ylabel=ylabel, title=title)\n",
    "    \n",
    "    \n",
    "def generate_tch_stats(tch, bins, xlabels, score_col, group_name):\n",
    "    \"\"\"\n",
    "    Convenience method for processing scr.csv statistics\n",
    "    \"\"\"\n",
    "    tch_pid = tch.groupby('pid', as_index=False).mean()\n",
    "    ylabel = \"Average daily touches\" \n",
    "    title = \"Average touch count for {} groups, significance at alpha=0.05\".format(group_name)\n",
    "    group, p_vals = build_csv_tables(tch_pid, ['touch_count'], bins, xlabels, score_col, group_name)\n",
    "    tch_mean = group.mean()['touch_count']\n",
    "    tch_std = group.std()['touch_count']\n",
    "    tch_p = p_vals['touch_count']\n",
    "    build_bar(mean_df=tch_mean, std_df=tch_std, p_val_df=tch_p, title=title, ylabel=ylabel)\n",
    "\n",
    "\n",
    "def generate_act_stats(act, bins, xlabels, score_col, group_name):\n",
    "    \"\"\"\n",
    "    Convenience method for processing act.csv statistics\n",
    "    \"\"\"\n",
    "    act_pid = act.groupby('pid', as_index=False).mean()\n",
    "    ylabel = \"Average daily readings (10 second intervals)\" \n",
    "    title = \"Average accelerometer activity for {} groups, significance at alpha=0.05\".format(group_name)\n",
    "    group, p = build_csv_tables(act_pid, act_cols, bins, xlabels, score_col, group_name, show_bar=True, ylabel=ylabel, title=title, width=0.8)\n",
    "    \n",
    "    \n",
    "def build_corr_mat(corrs, p_vals, labels, title, alpha):\n",
    "    \"\"\"\n",
    "    returns the matplotlib plt object for the specified correlations.\n",
    "    \"\"\"\n",
    "    plt.rcParams[\"figure.figsize\"] = [20,12]\n",
    "    plt.imshow(corrs)\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = \"{0:.2f}\".format(r_corrs[i, j])\n",
    "            p = p_vals[i,j]\n",
    "            if p < alpha / len(labels):\n",
    "                text = text + \"*\"\n",
    "            plt.text(j,i, text, ha=\"center\", va=\"center\", color=\"w\")\n",
    "    plt.xticks([x for x in range(len(labels))], labels, rotation=45, ha=\"right\", rotation_mode='anchor')\n",
    "    plt.yticks([x for x in range(len(labels))], labels)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    return plt\n",
    "\n",
    "\n",
    "def run_r_corr(df, corr_type='spearman', p_correction='BH'):\n",
    "    \"\"\"\n",
    "    Runs R correlation calculations and p-value corrections on the given dataframe.\n",
    "    \n",
    "    :returns: a tuple of (correlations, counts, p_values)\n",
    "    \"\"\"\n",
    "    num_cols = len(df.columns.values)\n",
    "    r_dataframe = pandas2ri.py2ri(df)\n",
    "    r_as = r['as.matrix']\n",
    "    rcorr = r['rcorr'] \n",
    "    r_p_adjust = r['p.adjust']\n",
    "    result = rcorr(r_as(r_dataframe), type=corr_type)\n",
    "    rho = result[0]\n",
    "    n = result[1]\n",
    "    p = result[2]\n",
    "    \n",
    "    if p_correction is not None:\n",
    "        p = r_p_adjust(p, p_correction)\n",
    "    r_corrs = pandas2ri.ri2py(rho)\n",
    "    r_p_vals = pandas2ri.ri2py(p)\n",
    "    r_counts = pandas2ri.ri2py(n)\n",
    "    r_p_vals = np.reshape(r_p_vals, (num_cols,num_cols))\n",
    "    return r_corrs, r_counts, r_p_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Jupyter notebook bloat\n",
    "\n",
    "- as opposed to a cell that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils import build_hist, ttest_df, build_bar, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- note that \"doing work\" may never happen on a particular research thread, hence the appeal of Jupyter notebooks for research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deliverables on a project\n",
    "\n",
    "- a paper or presentation (but what goes into a paper?)\n",
    "    - graphs\n",
    "    - experimental results\n",
    "- possibly a code package!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### My workflow (a work in progress)\n",
    "\n",
    "0. Create dedicated conda env, git repository\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Data exploration\n",
    "\n",
    "1. Explore data in Jupyter notebook\n",
    "2. Migrate common functions into modules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Computation\n",
    "\n",
    "3. Sanity check code with tests\n",
    "4. Parameterize modules, write scripts as experiment \"code trails\"\n",
    "5. Things often don't work, but iterate on experiment runs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Deliverables\n",
    "\n",
    "6. Once things work, process output and generate figures in Jupyter notebook\n",
    "7. Document repository with steps to reproduce results in paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Workflow: what works for you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "- [Google-style docstrings](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html)\n",
    "- [Sphinx documentation](http://www.sphinx-doc.org/en/master/)\n",
    "- [unittest documentation](https://docs.python.org/3/library/unittest.html)\n",
    "- [Atlassian Git Feature Branch Workflow](https://www.atlassian.com/git/tutorials/comparing-workflows/feature-branch-workflow)\n",
    "- [Git User Manual](https://git-scm.com/docs/user-manual.html)\n",
    "- [GNU Make Manual](https://www.gnu.org/software/make/manual/html_node/index.html#SEC_Contents)\n",
    "- [argparse documentation](https://docs.python.org/3/library/argparse.html)\n",
    "- [tmux cheat sheet](https://tmuxcheatsheet.com/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
