{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Code Workflows and Python Tooling for Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## My experience: a balancing act\n",
    "\n",
    "<center><img src=\"images/ss_shipit.jpg\" width=\"500\"></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- \"just shipping it\" vs. \"coding the *right way*\"\n",
    "- improving workflows is a process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- \"just ship it\" mentality\n",
    "- \"technical debt\" analogy: the uncertainty of research makes taking on technical debt that much easier\n",
    "- try to start building habits that make \"doing things the right way\" efficient\n",
    "- it is a process: don't expect yourself to change all at once, make incremental improvements in workflow\n",
    "- also about building the right habits\n",
    "- will go through some easy things to always do, some things to try and incorporate into your workflow, as well as some more involved setups\n",
    "- will focus on Python here, but the same tooling exists and principles apply to other languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "- Documentation\n",
    "- Testing\n",
    "- Version Control\n",
    "- Automation\n",
    "- Reproducibility\n",
    "- Workflow Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Documentation\n",
    "\n",
    "1. Comment __while__ you code\n",
    "2. Ideally, follow a Docstring style\n",
    "3. Consider documentation generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Write comments as you go: your future self will thank you\n",
    "- Use inline comments `#` to provide context\n",
    "- Use docstrings `\"\"\" \"\"\"` to describe the behavior of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Not good\n",
    "def f(n):\n",
    "    return 1 << n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Better\n",
    "def power_of_two(n):\n",
    "    \"\"\"Calculates 2^n.\"\"\"\n",
    "    \n",
    "    # left bit shift by n equivalent to 2^n.\n",
    "    return 1 << n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function power_of_two in module __main__:\n",
      "\n",
      "power_of_two(n)\n",
      "    Calculates 2^n.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(power_of_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Disclaimer: do not reinvent the wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def power_of_two(n):\n",
    "    \"\"\"Calculates 2^n, but n can be negative and non-integer now!\"\"\"\n",
    "    return np.power(2, n) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Docstring styles\n",
    "\n",
    "- reST, Numpy, Google standardized documentation styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Google-style docstrings\n",
    "def power_of_two(n):\n",
    "    \"\"\"(Short description): Calculates 2^n.\n",
    "    \n",
    "    (Longer description): Calculates non-negative powers of two via bit shift.\n",
    "    \n",
    "    Args:\n",
    "        n (int): the exponent to raise 2 to.\n",
    "    Returns:\n",
    "        int: 2^n.\n",
    "    Raises:\n",
    "       ValueError: if n < 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    # left bit shift by n equivalent to 2^n.\n",
    "    return 1 << n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function power_of_two in module __main__:\n",
      "\n",
      "power_of_two(n)\n",
      "    (Short description): Calculates 2^n.\n",
      "    \n",
      "    (Longer description): Calculates non-negative powers of two via bit shift.\n",
      "    \n",
      "    Args:\n",
      "        n (int): the exponent to raise 2 to.\n",
      "    Returns:\n",
      "        int: 2^n.\n",
      "    Raises:\n",
      "       ValueError: if n < 0.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(power_of_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consider documentation generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def power_of_two(n):\n",
      "    \"\"\"Calculates :math:`2^n`.\n",
      "    \n",
      "    Calculates non-negative powers of two via bit shift.\n",
      "    \n",
      "    Args:\n",
      "        n (int): the exponent to raise 2 to.\n",
      "    Returns:\n",
      "        int: :math:`2^n`.\n",
      "    Raises:\n",
      "       ValueError: if :math:`n \\lt 0`.\n",
      "    \"\"\"\n",
      "    \n",
      "    # left bit shift by n equivalent to 2^n.\n",
      "    return 1 << n\n",
      "make: Entering directory '/mnt/c/Users/1994t/Documents/Github/code-workflow-lab-teaching/sphinx_demo'\n",
      "\u001b[01mRunning Sphinx v1.8.5\u001b[39;49;00m\n",
      "\u001b[01mloading pickled environment... \u001b[39;49;00mdone\n",
      "\u001b[01mbuilding [mo]: \u001b[39;49;00mtargets for 0 po files that are out of date\n",
      "\u001b[01mbuilding [html]\u001b[39;49;00m: targets for 0 source files that are out of date\n",
      "\u001b[01mupdating environment: \u001b[39;49;00m0 added, 0 changed, 0 removed\n",
      "\u001b[01mlooking for now-outdated files... \u001b[39;49;00mnone found\n",
      "\u001b[01mno targets are out of date.\u001b[39;49;00m\n",
      "\u001b[01mbuild succeeded.\u001b[39;49;00m\n",
      "\n",
      "The HTML pages are in _build/html.\n",
      "make: Leaving directory '/mnt/c/Users/1994t/Documents/Github/code-workflow-lab-teaching/sphinx_demo'\n"
     ]
    }
   ],
   "source": [
    "! cat sphinx_demo/code/power_of_two.py\n",
    "! make -C sphinx_demo html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"images/sphinx_doc.PNG\" width=\"1500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Testing\n",
    "\n",
    "\"The first principle is that you must not fool yourself — and you are the easiest person to fool.\" — Richard Feynman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- defensive coding\n",
    "- research code scares me -- since in scientific settings what is \"correct\" may be unclear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Testing\n",
    "\n",
    "1. Think about what your code \"should do\"\n",
    "2. Write dedicated tests while you code\n",
    "3. Consider testing frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- we all write tests -- little print statements to verify the output, etc\n",
    "- but we end up throwing them away"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Test-driven development mindset\n",
    "\n",
    "- write code to pass tests -> makes coding sessions more directed\n",
    "- forces you to think about failure points in your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fizzbuzz example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- `fizzbuzz` function, on input `n`:\n",
    "    - if n is divisible by 3, print \"fizz\"\n",
    "    - if n is divisible by 5, print \"buzz\"\n",
    "    - if n is divisible by both 3 and 5, print \"fizzbuzz\"\n",
    "    - otherwise, output n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def fizzbuzz(n):\n",
    "    if n % 15 == 0: return 'fizzbuzz'\n",
    "    if n % 3 == 0: return 'fizz'\n",
    "    if n % 5 == 0: return 'buzz'\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# assert statements are your friend\n",
    "assert fizzbuzz(3) == 'fizz', 'fails divides by 3 case'\n",
    "assert fizzbuzz(5) == 'buzz', 'fails divides by 5 case'\n",
    "assert fizzbuzz(15) == 'fizzbuzz', 'fails divides by 15 case'\n",
    "assert fizzbuzz(1) == 1, 'fails else case'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- don't delete the assert statements! They help you regression test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Docstrings part II: testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def fizzbuzz(n):\n",
    "    \"\"\"Performs the fizzbuzz function on input n.\n",
    "    \n",
    "    Doctests for regression testing, and examples of usage:\n",
    "    \n",
    "    >>> fizzbuzz(3)\n",
    "    'fizz'\n",
    "    >>> fizzbuzz(5)\n",
    "    'buzz'\n",
    "    >>> fizzbuzz(15)\n",
    "    'fizzbuzz'\n",
    "    >>> fizzbuzz(1)\n",
    "    1\n",
    "    \"\"\"\n",
    "    out = \"\"\n",
    "    if n % 3 == 0: out += \"fizz\"\n",
    "    if n % 5 == 0: out += \"buzz\"\n",
    "    return out if len(out) > 0 else n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    fizzbuzz(3)\n",
      "Expecting:\n",
      "    'fizz'\n",
      "ok\n",
      "Trying:\n",
      "    fizzbuzz(5)\n",
      "Expecting:\n",
      "    'buzz'\n",
      "ok\n",
      "Trying:\n",
      "    fizzbuzz(15)\n",
      "Expecting:\n",
      "    'fizzbuzz'\n",
      "ok\n",
      "Trying:\n",
      "    fizzbuzz(1)\n",
      "Expecting:\n",
      "    1\n",
      "ok\n",
      "7 items had no tests:\n",
      "    __main__\n",
      "    __main__.FeatureExtractTests\n",
      "    __main__.FeatureExtractTests.assert_frame_equal_dict\n",
      "    __main__.FeatureExtractTests.setUp\n",
      "    __main__.FeatureExtractTests.test_init_feature_df\n",
      "    __main__.f\n",
      "    __main__.power_of_two\n",
      "1 items passed all tests:\n",
      "   4 tests in __main__.fizzbuzz\n",
      "4 tests in 8 items.\n",
      "4 passed and 0 failed.\n",
      "Test passed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=4)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.testmod(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consider testing frameworks like `unittest`\n",
    "\n",
    "- provides automation, shared setup/teardown of tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Unit tests for feature extraction methods.\n",
    "\n",
    "\n",
    "Test contact hashes are:\n",
    "['1002060a7f4fe408f8137f12982e5d64cf34693',\n",
    "'10413044ad5f1183e38f5ddf17259326e976231']\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unittest\n",
    "\n",
    "class FeatureExtractTests(unittest.TestCase):\n",
    "\n",
    "    def assert_frame_equal_dict(self, actual_df, expected_dict, columns, check_dtype=True):\n",
    "        \"\"\"Helper function for doing df to dict comparison on the given columns.\"\"\"\n",
    "\n",
    "        expected_df = pd.DataFrame.from_dict(expected_dict).T\n",
    "        expected_df.columns = columns\n",
    "\n",
    "        pd.testing.assert_frame_equal(actual_df[columns],\n",
    "                                      expected_df,\n",
    "                                      check_dtype=check_dtype)\n",
    "\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"Populates test DataFrames common to all test cases.\"\"\"\n",
    "        self.pid1 = '1002060'\n",
    "        self.pid2 = '1041304'\n",
    "\n",
    "        self.combined_hash1 = '1002060a7f4fe408f8137f12982e5d64cf34693'\n",
    "        self.combined_hash2 = '10413044ad5f1183e38f5ddf17259326e976231'\n",
    "\n",
    "        with open(\"../data/test_comm.df\", 'rb') as comm_file:\n",
    "            self.raw_df = pickle.load(comm_file)\n",
    "            self.call_df = self.raw_df.loc[self.raw_df['comm_type'] == 'PHONE']\n",
    "            self.sms_df = self.raw_df.loc[self.raw_df['comm_type'] == 'SMS']\n",
    "\n",
    "        with open(\"../data/test_emm.df\", 'rb') as emm_file:\n",
    "            self.emm_df = pickle.load(emm_file)\n",
    "\n",
    "\n",
    "    def test_init_feature_df(self):\n",
    "        \"\"\"\"Tests init_feature_df function.\n",
    "        \n",
    "        Checks whether total_comms, total_comm_days, and contact_type columns are populated correctly.\n",
    "        \"\"\"\n",
    "        expected_dict = {\n",
    "            (self.pid1, self.combined_hash1): [8, 2, 'friend'],\n",
    "            (self.pid2, self.combined_hash2): [6, 3, 'family_live_together']\n",
    "        }\n",
    "\n",
    "        expected_df = pd.DataFrame.from_dict(expected_dict).T\n",
    "        expected_df.index = expected_df.index.rename(['pid', 'combined_hash'])\n",
    "        expected_df = expected_df.rename({\n",
    "                                            0: \"total_comms\",\n",
    "                                            1: \"total_comm_days\",\n",
    "                                            2: \"contact_type\"\n",
    "                                         },\n",
    "                                         axis='columns')\n",
    "        expected_df['total_comms'] = expected_df['total_comms'].astype(int)\n",
    "        expected_df['total_comm_days'] = expected_df['total_comm_days'].astype(int)\n",
    "        \n",
    "        actual_df = init_feature_df(self.raw_df)\n",
    "\n",
    "        pd.testing.assert_frame_equal(actual_df, expected_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "(code-workflow) tliu@DESKTOP-3QP831J:feature_extract$ python test_feature_extract.py -v\n",
    "test_build_avoidance_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_channel_selection_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_count_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_demo_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_duration_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_holiday_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_intensity_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_maintenance_features (__main__.FeatureExtractTests) ... ok\n",
    "test_build_temporal_features (__main__.FeatureExtractTests) ... ok\n",
    "test_filter_by_holiday (__main__.FeatureExtractTests) ... ok\n",
    "test_init_feature_df (__main__.FeatureExtractTests) ... ok\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Ran 11 tests in 2.086s\n",
    "\n",
    "OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Version Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Version Control\n",
    "\n",
    "0. Use it!\n",
    "1. Commit messages should be informative\n",
    "2. Ideally subdivide tasks into concrete commits\n",
    "3. Consider branching strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Commit Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<center><img src=\"images/bad_commits.PNG\" width=\"500\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Commit Messages\n",
    "\n",
    "- Summarize commit in brief, imperative statement\n",
    "- Use commit body for more details if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consider Development Branches\n",
    "\n",
    "- treat `master` as \"protected\" branch\n",
    "- work on new features in separate branches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Development Branch Workflow\n",
    "\n",
    "![](images/feature_branch_01.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# create new branch, dev-branch\n",
    "git checkout -b dev-branch master\n",
    "\n",
    "# do work\n",
    "git add ...\n",
    "git commit ...\n",
    "\n",
    "# push to remote dev-branch, open PR\n",
    "git push origin dev-branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](images/feature_branch_02.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Thoughts on Code Review\n",
    "\n",
    "- \"could you read my paper draft?\" -> \"could you review my code?\"\n",
    "\n",
    "<center><img src=\"images/code_review.PNG\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automation \n",
    "\n",
    "1. Move your work out of \"interactive mode\" as often as possible\n",
    "2. Ideally batch process computation\n",
    "3. Consider workflow automation tools like `make`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `argparse` is your friend\n",
    "\n",
    "- allows parameterization of entire modules\n",
    "- another form of documentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"Extract data from Optum raw files and dump to DataFrames\")\n",
    "parser.add_argument('data_dir', help='directory with all Optum data')\n",
    "parser.add_argument('yr', help='the year to target')\n",
    "parser.add_argument('q', help='the quarter to target')\n",
    "parser.add_argument('out_dir', help='output directory')\n",
    "parser.add_argument('table_type', choices=['m', 'lr', 'r'], help='Optum table type to target: medical (m), lab reports (lr), prescriptions (r)')\n",
    "parser.add_argument('chunksize', type=int, help='number of rows to read per chunk')\n",
    "parser.add_argument('--test', action='store_true', help='whether to make a test run of the data extraction')\n",
    "parser.add_argument('--m_dm_outcome', action='store_true', help='perform diabetes med outcome extraction')\n",
    "parser.add_argument('--rx_dm', action='store_true', help='perform diabetes rx extraction')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: med_extract.py [-h] [--test] [--m_dm_outcome] [--rx_dm]\r\n",
      "                      data_dir yr q out_dir {m,lr,r} chunksize\r\n",
      "\r\n",
      "Extract data from Optum raw files and dump to DataFrames\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  data_dir        directory with all Optum data\r\n",
      "  yr              the year to target\r\n",
      "  q               the quarter to target\r\n",
      "  out_dir         output directory\r\n",
      "  {m,lr,r}        Optum table type to target: medical (m), lab reports (lr),\r\n",
      "                  prescriptions (r)\r\n",
      "  chunksize       number of rows to read per chunk\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help      show this help message and exit\r\n",
      "  --test          whether to make a test run of the data extraction\r\n",
      "  --m_dm_outcome  perform diabetes med outcome extraction\r\n",
      "  --rx_dm         perform diabetes rx extraction\r\n"
     ]
    }
   ],
   "source": [
    "! python scripting_demo/med_extract.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- argparse is yet another form of documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# nohup means ignore hangup (logouts), ampersand means run in the background\n",
    "nohup python batch_example.py &\n",
    "\n",
    "# alternatively, use tmux/screen window managers\n",
    "tmux new -s batch_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- much better than running python ... (especially better than running a computation in jupyter)\n",
    "- more sophisticated way of scheduling jobs in the background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consider `make` for complex workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- used for building software, can be also used for data transformation\n",
    "- disclaimer: I haven't yet encountered a workflow in my research career that make makes significantly easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# command from earlier to build documentation\n",
    "sphinx-build . _build -b html\n",
    "\n",
    "# Makefile equivalent\n",
    "make html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Minimal makefile for Sphinx documentation\r\n",
      "#\r\n",
      "\r\n",
      "# You can set these variables from the command line.\r\n",
      "SPHINXOPTS    =\r\n",
      "SPHINXBUILD   = sphinx-build\r\n",
      "SOURCEDIR     = .\r\n",
      "BUILDDIR      = _build\r\n",
      "\r\n",
      "# Put it first so that \"make\" without argument is like \"make help\".\r\n",
      "help:\r\n",
      "\t@$(SPHINXBUILD) -M help \"$(SOURCEDIR)\" \"$(BUILDDIR)\" $(SPHINXOPTS) $(O)\r\n",
      "\r\n",
      ".PHONY: help Makefile\r\n",
      "\r\n",
      "# Catch-all target: route all unknown targets to Sphinx using the new\r\n",
      "# \"make mode\" option.  $(O) is meant as a shortcut for $(SPHINXOPTS).\r\n",
      "%: Makefile\r\n",
      "\t@$(SPHINXBUILD) -M $@ \"$(SOURCEDIR)\" \"$(BUILDDIR)\" $(SPHINXOPTS) $(O)"
     ]
    }
   ],
   "source": [
    "! cat sphinx_demo/Makefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reproducibility\n",
    "\n",
    "1. Parameterize code to facilitate A/B testing\n",
    "2. Ideally, track and parameterize your environment too\n",
    "3. Consider Docker for more complex builds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bash scripts\n",
    "\n",
    "- Code form of an experimental procedure\n",
    "- gives us a mechanism to track changes in runs, A/B testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "\r\n",
      "# AutoML random forest runs for tie strength score prediction\r\n",
      "python run_automl.py \\\r\n",
      "       ../data/final_features/all_tie_str_baseline \\   # input features\r\n",
      "       final_results/tie_str/tie_str_baseline_rf_reg \\ # output name\r\n",
      "       tie_str_score \\                                 # outcome variable (regression)\r\n",
      "       --run_time 1440 --task_time 21600 \\             # training time\r\n",
      "       --rand_forest \\                                 # only train random forest estimators\r\n",
      "       > tie_str_baseline_rf_reg.out;\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! cat scripting_demo/tie_str_rf_reg.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tracking your environment\n",
    "\n",
    "- use `virtualenv` or `conda` to make your environments portable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                     /home/tliu/miniconda3\r\n",
      "code-workflow         *  /home/tliu/miniconda3/envs/code-workflow\r\n",
      "py37                     /home/tliu/miniconda3/envs/py37\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: code-workflow\r\n",
      "channels:\r\n",
      "  - conda-forge\r\n",
      "  - anaconda\r\n",
      "  - defaults\r\n",
      "dependencies:\r\n",
      "  - alabaster=0.7.12=py37_0\r\n",
      "  - asn1crypto=0.24.0=py37_0\r\n",
      "  - babel=2.6.0=py37_0\r\n",
      "  - blas=1.0=mkl\r\n",
      "  - cffi=1.12.2=py37h2e261b9_1\r\n",
      "  - chardet=3.0.4=py37_1\r\n",
      "  - cryptography=2.6.1=py37h1ba5d50_0\r\n",
      "  - docutils=0.14=py37_0\r\n",
      "  - idna=2.8=py37_0\r\n",
      "  - imagesize=1.1.0=py37_0\r\n",
      "  - intel-openmp=2019.3=199\r\n",
      "  - libgfortran-ng=7.3.0=hdf63c60_0\r\n",
      "  - mkl=2019.3=199\r\n",
      "  - mkl_fft=1.0.10=py37ha843d7b_0\r\n",
      "  - mkl_random=1.0.2=py37hd81dba3_0\r\n",
      "  - numpy=1.16.2=py37h7e9f1db_0\r\n",
      "  - numpy-base=1.16.2=py37hde5b4d6_0\r\n",
      "  - packaging=19.0=py37_0\r\n",
      "  - pandas=0.24.2=py37he6710b0_0\r\n",
      "  - pycparser=2.19=py37_0\r\n",
      "  - pyopenssl=19.0.0=py37_0\r\n",
      "  - pyparsing=2.3.1=py37_0\r\n",
      "  - pysocks=1.6.8=py37_0\r\n",
      "  - pytz=2018.9=py37_0\r\n",
      "  - requests=2.21.0=py37_0\r\n",
      "  - snowballstemmer=1.2.1=py37_0\r\n",
      "  - sphinx=1.8.5=py37_0\r\n",
      "  - sphinxcontrib=1.0=py37_1\r\n",
      "  - sphinxcontrib-websupport=1.1.0=py37_1\r\n",
      "  - urllib3=1.24.1=py37_0\r\n",
      "  - attrs=19.1.0=py_0\r\n",
      "  - backcall=0.1.0=py_0\r\n",
      "  - bleach=3.1.0=py_0\r\n",
      "  - decorator=4.4.0=py_0\r\n",
      "  - defusedxml=0.5.0=py_1\r\n",
      "  - entrypoints=0.3=py37_1000\r\n",
      "  - expat=2.2.5=hf484d3e_1002\r\n",
      "  - fontconfig=2.13.1=he4413a7_1000\r\n",
      "  - freetype=2.10.0=he983fc9_0\r\n",
      "  - gettext=0.19.8.1=hc5be6a0_1002\r\n",
      "  - glib=2.56.2=had28632_1001\r\n",
      "  - icu=58.2=hf484d3e_1000\r\n",
      "  - ipykernel=5.1.0=py37h24bf2e0_1002\r\n",
      "  - ipython=7.4.0=py37h24bf2e0_0\r\n",
      "  - ipython_genutils=0.2.0=py_1\r\n",
      "  - ipywidgets=7.4.2=py_0\r\n",
      "  - jedi=0.13.3=py37_0\r\n",
      "  - jinja2=2.10=py_1\r\n",
      "  - jpeg=9c=h14c3975_1001\r\n",
      "  - jsonschema=3.0.1=py37_0\r\n",
      "  - jupyter=1.0.0=py_1\r\n",
      "  - jupyter_client=5.2.4=py_3\r\n",
      "  - jupyter_console=6.0.0=py_0\r\n",
      "  - jupyter_contrib_core=0.3.3=py_2\r\n",
      "  - jupyter_core=4.4.0=py_0\r\n",
      "  - jupyter_nbextensions_configurator=0.4.1=py37_0\r\n",
      "  - libiconv=1.15=h516909a_1005\r\n",
      "  - libpng=1.6.36=h84994c4_1000\r\n",
      "  - libsodium=1.0.16=h14c3975_1001\r\n",
      "  - libuuid=2.32.1=h14c3975_1000\r\n",
      "  - libxcb=1.13=h14c3975_1002\r\n",
      "  - libxml2=2.9.8=h143f9aa_1005\r\n",
      "  - markupsafe=1.1.1=py37h14c3975_0\r\n",
      "  - mistune=0.8.4=py37h14c3975_1000\r\n",
      "  - nbconvert=5.4.1=py_2\r\n",
      "  - nbformat=4.4.0=py_1\r\n",
      "  - notebook=5.7.6=py37_0\r\n",
      "  - pandoc=2.7.1=0\r\n",
      "  - pandocfilters=1.4.2=py_1\r\n",
      "  - parso=0.3.4=py_0\r\n",
      "  - pexpect=4.6.0=py37_1000\r\n",
      "  - pickleshare=0.7.5=py37_1000\r\n",
      "  - prometheus_client=0.6.0=py_0\r\n",
      "  - prompt_toolkit=2.0.9=py_0\r\n",
      "  - pthread-stubs=0.4=h14c3975_1001\r\n",
      "  - ptyprocess=0.6.0=py37_1000\r\n",
      "  - pygments=2.3.1=py_0\r\n",
      "  - pyqt=5.6.0=py37h13b7fb3_1008\r\n",
      "  - pyrsistent=0.14.11=py37h14c3975_0\r\n",
      "  - python-dateutil=2.8.0=py_0\r\n",
      "  - pyyaml=5.1=py37h14c3975_0\r\n",
      "  - pyzmq=18.0.1=py37h0e1adb2_0\r\n",
      "  - qtconsole=4.4.3=py_0\r\n",
      "  - rise=5.4.1=py37_1000\r\n",
      "  - send2trash=1.5.0=py_0\r\n",
      "  - sip=4.18.1=py37hf484d3e_1000\r\n",
      "  - six=1.12.0=py37_1000\r\n",
      "  - terminado=0.8.1=py37_1001\r\n",
      "  - testpath=0.4.2=py_1001\r\n",
      "  - tornado=6.0.2=py37h516909a_0\r\n",
      "  - traitlets=4.3.2=py37_1000\r\n",
      "  - wcwidth=0.1.7=py_1\r\n",
      "  - webencodings=0.5.1=py_1\r\n",
      "  - widgetsnbextension=3.4.2=py37_1000\r\n",
      "  - xorg-libxau=1.0.9=h14c3975_0\r\n",
      "  - xorg-libxdmcp=1.1.3=h516909a_0\r\n",
      "  - yaml=0.1.7=h14c3975_1001\r\n",
      "  - zeromq=4.2.5=hf484d3e_1006\r\n",
      "  - ca-certificates=2019.1.23=0\r\n",
      "  - certifi=2019.3.9=py37_0\r\n",
      "  - dbus=1.13.2=h714fa37_1\r\n",
      "  - gst-plugins-base=1.14.0=hbbd80ab_1\r\n",
      "  - gstreamer=1.14.0=hb453b48_1\r\n",
      "  - libedit=3.1.20181209=hc058e9b_0\r\n",
      "  - libffi=3.2.1=hd88cf55_4\r\n",
      "  - libgcc-ng=8.2.0=hdf63c60_1\r\n",
      "  - libstdcxx-ng=8.2.0=hdf63c60_1\r\n",
      "  - ncurses=6.1=he6710b0_1\r\n",
      "  - openssl=1.1.1b=h7b6447c_1\r\n",
      "  - pcre=8.43=he6710b0_0\r\n",
      "  - pip=19.0.3=py37_0\r\n",
      "  - python=3.7.2=h0371630_0\r\n",
      "  - qt=5.6.3=h8bf5577_3\r\n",
      "  - readline=7.0=h7b6447c_5\r\n",
      "  - setuptools=40.8.0=py37_0\r\n",
      "  - sqlite=3.27.2=h7b6447c_0\r\n",
      "  - tk=8.6.8=hbc83047_0\r\n",
      "  - wheel=0.33.1=py37_0\r\n",
      "  - xz=5.2.4=h14c3975_4\r\n",
      "  - zlib=1.2.11=h7b6447c_3\r\n",
      "  - pip:\r\n",
      "    - pockets==0.7.2\r\n",
      "    - sphinxcontrib-napoleon==0.7\r\n",
      "prefix: /home/tliu/miniconda3/envs/code-workflow\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! conda env export > environment.yml\n",
    "! cat environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consider Docker for complex environments\n",
    "\n",
    "- port, share and reproduce \"OS-level\" configurations\n",
    "    - custom library installations (eg, CUDA)\n",
    "    - UNIX tooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Jupyter notebooks are __notebooks__\n",
    "\n",
    "- good for exploring the data\n",
    "- good for presenting and visualizing results\n",
    "- bad for \"doing work\" in between"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Jupyter notebook bloat\n",
    "\n",
    "- A cell that looks like [this](https://gist.github.com/tliu526/6e23aa99a323646be98691fb6d6a0f55):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# bad notebook cell\n",
    "def build_hist(series, bins, xtick_labels, xlabel, title):\n",
    "    \"\"\"Builds custom histogram with bar labels and equal bin sizes\n",
    "    \n",
    "    :param series: pandas series to bin\n",
    "    :param bins: list of bin sizes\n",
    "    :param xtick_labels: list of labels for xticks\n",
    "    :param xlabel: x-axis str label\n",
    "    :param title: str title\n",
    "    \"\"\"\n",
    "    counts, _ = np.histogram(series.values, bins=bins)\n",
    "    rects = plt.bar(range(len(counts)), counts, width=0.5, tick_label=counts)\n",
    "    for r in rects: \n",
    "        h = r.get_height()\n",
    "        plt.text(r.get_x() + r.get_width()/2, 1.01*h, h, ha='center')\n",
    "    plt.xticks(range(len(counts)), xtick_labels)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"# participants\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def get_score(row, source_df, score_name):\n",
    "    \"\"\"Maps the score_name score from the given source DataFrame to a row by pid.\n",
    "    \n",
    "    To be used via DataFrame.apply().\n",
    "    \n",
    "    Example usage: \n",
    "    >>> all_df['score_AUDIT'] = all_df.apply(get_score, \n",
    "                                             source_df=screener_df, \n",
    "                                             score_name='score_AUDIT',\n",
    "                                             axis=1)\n",
    "    \"\"\"\n",
    "    \n",
    "    return source_df[source_df['pid'] == row.pid][score_name].values[0]\n",
    "\n",
    "\n",
    "def build_ttest_dfs(pid_df, group_col, val_cols):\n",
    "    \"\"\"Runs t-tests on the given pid_df DataFrame against the groupings as defined in group_col.\n",
    "    \n",
    "    :param pid_df: a DataFrame aggregated by participant pids\n",
    "    :param group_col: the column name to group on\n",
    "    :param val_cols: the columns we want to run t-tests on\n",
    "    :returns: t_df, p_df DataFrames containing the t and p values\n",
    "    \"\"\"\n",
    "    index = pd.Index(data=pid_df[group_col].unique(), name=group_col).sort_values()\n",
    "    t_df = pd.DataFrame(index = index, columns = val_cols)\n",
    "    p_df = pd.DataFrame(index = index, columns = val_cols)\n",
    "\n",
    "    for group in pid_df[group_col].unique():\n",
    "        selected_group = pid_df[pid_df[group_col] == group]\n",
    "        rest_group =  pid_df[pid_df[group_col] != group]\n",
    "        for col in val_cols:\n",
    "            t, p = ttest_ind(selected_group[col].values, \n",
    "                             rest_group[col].values, \n",
    "                             nan_policy='omit')\n",
    "\n",
    "            t_df.loc[group][col] = t\n",
    "            p_df.loc[group][col] = p\n",
    "    \n",
    "    for col in p_df.columns.values:\n",
    "            t_df[col] = t_df[col].apply(lambda x: format(float(x), '.3f'))\n",
    "            p_df[col] = p_df[col].apply(lambda x: format(float(x), '.3f'))\n",
    "    return t_df, p_df\n",
    "\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "    \"\"\"Concats the given DataFrame args to a single df\"\"\"\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        #for col in df.col.values:\n",
    "        #    df[col] = df[col].apply(lambda x: format(float(x), '2.3d'))\n",
    "        html_str+=df._repr_html_()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
    "    \n",
    "\n",
    "def build_csv_tables(csv_pid, csv_cols, bins, xlabels, score_col, group_col, show_bar=False, ylabel=\"\", title=\"\", alpha=0.05, width=0.7):\n",
    "    \"\"\"Builds and displays descriptive statistics for the given csv Dataframe.\n",
    "    \n",
    "    :param csv_pid: DataFrame grouped by pid\n",
    "    :param csv_cols: the target csv column values to display\n",
    "    :param bins: the bins defined for the disorder score\n",
    "    :param xlabels: labels for each bin\n",
    "    :param score_col: the col name for the disorder score\n",
    "    :param group_col: the chosen group name for the bins\n",
    "    \"\"\"\n",
    "    csv_pid[group_col] = pd.cut(csv_pid[score_col], bins, labels=xlabels)\n",
    "    csv_pid = csv_pid.dropna(subset=[group_col])\n",
    "    csv_group = csv_pid.groupby(group_col)[csv_cols]\n",
    "\n",
    "    t, p = build_ttest_dfs(csv_pid, group_col, csv_cols)\n",
    "\n",
    "    display_side_by_side(csv_group.mean().style.set_caption(\"mean\"), \n",
    "                         csv_group.std().style.set_caption(\"std dev\"),\n",
    "                         p.style.set_caption(\"p-values\"))\n",
    "\n",
    "    \n",
    "    if show_bar:\n",
    "        yerr=csv_group.std().T\n",
    "        ax = csv_group.mean().T.plot.bar(yerr=yerr, width=width, rot=0)\n",
    "        p_list = p.values.flatten()\n",
    "        std_list = csv_group.std().values.flatten()\n",
    "        for i, bar in enumerate(ax.patches):\n",
    "            sig = \"*\" if float(p_list[i]) < alpha else \"\"\n",
    "            height = bar.get_height()\n",
    "            text = format(height, \".2f\") + sig\n",
    "            ax.annotate(text, (bar.get_x() + bar.get_width()/2, (height + std_list[i])*1.01), ha='center')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.title(title)\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "        \n",
    "    return csv_group, p\n",
    "\n",
    "\n",
    "def build_bar(std_df, mean_df, p_val_df, ylabel=\"\", title=\"\", alpha=0.05, show_legend=False):\n",
    "    \"\"\"Builds a bar chart with the given DataFrames\"\"\"\n",
    "    yerr=std_df.T\n",
    "    ax = mean_df.T.plot.bar(yerr=yerr, width=0.7, rot=0)\n",
    "    p_list = p_val_df.values.flatten()\n",
    "    std_list = std_df.values.flatten()\n",
    "    for i, bar in enumerate(ax.patches):\n",
    "        sig = \"*\" if float(p_list[i]) < alpha else \"\"\n",
    "        height = bar.get_height()\n",
    "        text = format(height, \".2f\") + sig\n",
    "        ax.annotate(text, (bar.get_x() + bar.get_width()/2, (height + std_list[i])*1.01), ha='center')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    if show_legend:\n",
    "        plt.legend(loc='lower right')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [15,6]\n",
    "\n",
    "\n",
    "def generate_ems_stats(ems_raw, bins, xlabels, score_col, group_name):\n",
    "    \"\"\"Convenience method for generating ems.csv statistics.\"\"\"\n",
    "    ems_pid = ems_raw.groupby('pid', as_index=False).mean()\n",
    "    group, p_vals = build_csv_tables(ems_pid, ems_cols, bins, xlabels, score_col, group_name, show_bar=False)\n",
    "    sleep_qual_mean = group.mean()['sleep_quality']\n",
    "    sleep_qual_std = group.std()['sleep_quality']\n",
    "    sleep_qual_p = p_vals['sleep_quality']\n",
    "    title = \"Average sleep quality for {} groups, significance* at alpha=0.05\".format(group_name)\n",
    "    ylabel = \"Average sleep quality 0-8 Likert\"\n",
    "    build_bar(mean_df=sleep_qual_mean, std_df=sleep_qual_std, p_val_df=sleep_qual_p, title=title, ylabel=ylabel)\n",
    "    \n",
    "\n",
    "def generate_emm_stats(emm_raw, bins, xlabels, score_col, group_name):\n",
    "    \"\"\"Convenience method for processing emm.csv statistics.\"\"\"\n",
    "    emm_pid = emm_raw.groupby('pid', as_index=False).mean()\n",
    "    ylabel = \"Average EMA score 0-8 Likert\" \n",
    "    title = \"Average EMA responses for {} groups, significance at alpha=0.05\".format(group_name)\n",
    "    group, p = build_csv_tables(emm_pid, emm_cols, bins, xlabels, score_col, group_name, show_bar=True, ylabel=ylabel, title=title)\n",
    "    \n",
    "\n",
    "def generate_coe_stats(coe, bins, xlabels, score_col, group_name):\n",
    "    \"\"\"Convenience method for processing coe.csv statistics\"\"\"\n",
    "    coe_pid = coe.groupby('pid', as_index=False).mean()\n",
    "    ylabel = \"Average daily frequency\" \n",
    "    title = \"Average communication daily counts for {} groups, significance at alpha=0.05\".format(group_name)\n",
    "    group, p = build_csv_tables(coe_pid, coe_cols, bins, xlabels, score_col, group_name, show_bar=True, ylabel=ylabel, title=title)\n",
    "    \n",
    "\n",
    "def generate_scr_stats(scr, bins, xlabels, score_col, group_name):\n",
    "    \"\"\"Convenience method for processing scr.csv statistics.\"\"\"\n",
    "    \n",
    "    scr_pid = scr.groupby('pid', as_index=False).mean()\n",
    "    ylabel = \"Average screen on hours\" \n",
    "    title = \"Average screen on time for {} groups, significance at alpha=0.05\".format(group_name)\n",
    "    group, p = build_csv_tables(scr_pid, ['screen_on'], bins, xlabels, score_col, group_name, show_bar=True, ylabel=ylabel, title=title)\n",
    "    \n",
    "    \n",
    "def generate_tch_stats(tch, bins, xlabels, score_col, group_name):\n",
    "    \"\"\"Convenience method for processing tch.csv statistics.\"\"\"\n",
    "    \n",
    "    tch_pid = tch.groupby('pid', as_index=False).mean()\n",
    "    ylabel = \"Average daily touches\" \n",
    "    title = \"Average touch count for {} groups, significance at alpha=0.05\".format(group_name)\n",
    "    group, p_vals = build_csv_tables(tch_pid, ['touch_count'], bins, xlabels, score_col, group_name)\n",
    "    tch_mean = group.mean()['touch_count']\n",
    "    tch_std = group.std()['touch_count']\n",
    "    tch_p = p_vals['touch_count']\n",
    "    build_bar(mean_df=tch_mean, std_df=tch_std, p_val_df=tch_p, title=title, ylabel=ylabel)\n",
    "\n",
    "\n",
    "def generate_act_stats(act, bins, xlabels, score_col, group_name):\n",
    "    \"\"\"Convenience method for processing act.csv statistics.\"\"\"\n",
    "    \n",
    "    act_pid = act.groupby('pid', as_index=False).mean()\n",
    "    ylabel = \"Average daily readings (10 second intervals)\" \n",
    "    title = \"Average accelerometer activity for {} groups, significance at alpha=0.05\".format(group_name)\n",
    "    group, p = build_csv_tables(act_pid, act_cols, bins, xlabels, score_col, group_name, show_bar=True, ylabel=ylabel, title=title, width=0.8)\n",
    "    \n",
    "    \n",
    "def build_corr_mat(corrs, p_vals, labels, title, alpha):\n",
    "    \"\"\"returns the matplotlib plt object for the specified correlations.\"\"\"\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = [20,12]\n",
    "    plt.imshow(corrs)\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = \"{0:.2f}\".format(r_corrs[i, j])\n",
    "            p = p_vals[i,j]\n",
    "            if p < alpha / len(labels):\n",
    "                text = text + \"*\"\n",
    "            plt.text(j,i, text, ha=\"center\", va=\"center\", color=\"w\")\n",
    "    plt.xticks([x for x in range(len(labels))], labels, rotation=45, ha=\"right\", rotation_mode='anchor')\n",
    "    plt.yticks([x for x in range(len(labels))], labels)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    return plt\n",
    "\n",
    "\n",
    "def run_r_corr(df, corr_type='spearman', p_correction='BH'):\n",
    "    \"\"\"Runs R correlation calculations and p-value corrections on the given dataframe.\n",
    "    \n",
    "    :returns: a tuple of (correlations, counts, p_values)\n",
    "    \"\"\"\n",
    "    num_cols = len(df.columns.values)\n",
    "    r_dataframe = pandas2ri.py2ri(df)\n",
    "    r_as = r['as.matrix']\n",
    "    rcorr = r['rcorr'] \n",
    "    r_p_adjust = r['p.adjust']\n",
    "    result = rcorr(r_as(r_dataframe), type=corr_type)\n",
    "    rho = result[0]\n",
    "    n = result[1]\n",
    "    p = result[2]\n",
    "    \n",
    "    if p_correction is not None:\n",
    "        p = r_p_adjust(p, p_correction)\n",
    "    r_corrs = pandas2ri.ri2py(rho)\n",
    "    r_p_vals = pandas2ri.ri2py(p)\n",
    "    r_counts = pandas2ri.ri2py(n)\n",
    "    r_p_vals = np.reshape(r_p_vals, (num_cols,num_cols))\n",
    "    return r_corrs, r_counts, r_p_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Jupyter notebook bloat\n",
    "\n",
    "- as opposed to a cell that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils import build_hist, ttest_df, build_bar, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- note that \"doing work\" may never happen on a particular research thread, hence the appeal of Jupyter notebooks for research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deliverables on a project\n",
    "\n",
    "- a paper or presentation (but what goes into a paper?)\n",
    "    - graphs\n",
    "    - experimental results\n",
    "- possibly a code package!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### My workflow (a work in progress)\n",
    "\n",
    "0. Create dedicated conda env, git repository\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Data exploration\n",
    "\n",
    "1. Explore data in Jupyter notebook\n",
    "2. Migrate common functions into modules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Computation\n",
    "\n",
    "3. Sanity check code with tests\n",
    "4. Parameterize modules, write scripts as experiment \"code trails\"\n",
    "5. Things often don't work, but iterate on experiment runs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Deliverables\n",
    "\n",
    "6. Once things work, process output and generate figures in Jupyter notebook\n",
    "7. Document repository with steps to reproduce results in paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Workflow: what works for you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "- [Google-style docstrings](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html)\n",
    "- [Sphinx documentation](http://www.sphinx-doc.org/en/master/)\n",
    "- [unittest documentation](https://docs.python.org/3/library/unittest.html)\n",
    "- [Atlassian Git Feature Branch Workflow](https://www.atlassian.com/git/tutorials/comparing-workflows/feature-branch-workflow)\n",
    "- [Git User Manual](https://git-scm.com/docs/user-manual.html)\n",
    "- [GNU Make Manual](https://www.gnu.org/software/make/manual/html_node/index.html#SEC_Contents)\n",
    "- [argparse documentation](https://docs.python.org/3/library/argparse.html)\n",
    "- [tmux cheat sheet](https://tmuxcheatsheet.com/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
